{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is the first version that Sam was working with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataset link: https://www.kaggle.com/datasets/ninadaithal/imagesoasis\n",
    "\n",
    "# Dataset path and class names\n",
    "dataset_path = './OASIS Data'\n",
    "\n",
    "# Verify access to dataset\n",
    "print(\"Accessing dataset...\")\n",
    "print(os.listdir(dataset_path))\n",
    "\n",
    "classes = ['Non Demented', 'Mild Dementia', 'Moderate Dementia', 'Very mild Dementia']\n",
    "image_paths = []\n",
    "labels = []\n",
    "\n",
    "num_files = 1464  # Number of files to select randomly from each category (number was chosen because there are only 488 images for moderate dementia)\n",
    "\n",
    "# Function to load images\n",
    "def load_images(paths, img_size=(224, 224)):\n",
    "    images = []\n",
    "    for path in paths:\n",
    "        try:\n",
    "            # Read image (grayscale for simplicity)\n",
    "            img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "            if img is None:\n",
    "                print(f\"Failed to load image: {path}\")\n",
    "                continue\n",
    "            img = cv2.resize(img, img_size)\n",
    "            img = img / 255.0  # Normalize to [0, 1]\n",
    "            images.append(img)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing image {path}: {str(e)}\")\n",
    "    return np.array(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Iterate through classes and load images\n",
    "    non_demented_path = os.path.join(dataset_path, 'Non Demented')\n",
    "    non_demented_files = os.listdir(non_demented_path)\n",
    "    # Randomly select a subset of images\n",
    "    non_demented_files = random.sample(non_demented_files, min(num_files, len(non_demented_files)))\n",
    "    \n",
    "    print(f\"Loaded {len(non_demented_files)} non-demented images\")\n",
    "\n",
    "    image_paths = []\n",
    "\n",
    "    for image_filename in non_demented_files:\n",
    "        image_path = os.path.join(non_demented_path, image_filename)\n",
    "        if os.path.isfile(image_path):\n",
    "            image_paths.append(image_path)\n",
    "            labels.append(0)  # Label for Non Demented\n",
    "\n",
    "    dementia_classes = ['Mild Dementia', 'Moderate Dementia', 'Very mild Dementia']\n",
    "    for category in dementia_classes:\n",
    "        try:\n",
    "            category_path = os.path.join(dataset_path, category)\n",
    "            category_files = os.listdir(category_path)\n",
    "            selected_files = random.sample(category_files, min(num_files // len(dementia_classes), len(category_files)))\n",
    "            for image_filename in selected_files:\n",
    "                image_path = os.path.join(category_path, image_filename)\n",
    "                if os.path.isfile(image_path):\n",
    "                    image_paths.append(image_path)\n",
    "                    labels.append(1)  # Label for Dementia (combined)\n",
    "            \n",
    "            print(f\"Loaded {len(selected_files)} images from {category}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing category {category}: {str(e)}\")\n",
    "\n",
    "    print(f\"Total images loaded: {len(image_paths)}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading image directories: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# V2: These Models are not being used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 1: Binary Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_binary_classifier(X_train, y_train, X_val, y_val):\n",
    "    # Data augmentation for training\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest'\n",
    "    )\n",
    "    \n",
    "    # Only rescaling for validation\n",
    "    val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "    \n",
    "    # Create generators\n",
    "    train_generator = train_datagen.flow(X_train, y_train, batch_size=32)\n",
    "    val_generator = val_datagen.flow(X_val, y_val, batch_size=32)\n",
    "    \n",
    "    # Build model\n",
    "    binary_model = Sequential([\n",
    "        Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 1), kernel_regularizer=l2(0.001)),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        \n",
    "        Conv2D(64, (3, 3), activation='relu', kernel_regularizer=l2(0.001)),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        \n",
    "        Conv2D(128, (3, 3), activation='relu', kernel_regularizer=l2(0.001)),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        \n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu', kernel_regularizer=l2(0.001)),\n",
    "        Dropout(0.5),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    # Compile model\n",
    "    binary_model.compile(\n",
    "        optimizer=Adam(learning_rate=0.0001),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    # Callbacks\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.00001)\n",
    "    \n",
    "    # Train model\n",
    "    history = binary_model.fit(\n",
    "        train_generator,\n",
    "        validation_data=val_generator,\n",
    "        epochs=20,\n",
    "        callbacks=[early_stopping, reduce_lr]\n",
    "    )\n",
    "    \n",
    "    return binary_model, history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 2: Multi-class Classification for Dementia Severity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_severity_classifier(X_train, y_train, X_val, y_val):\n",
    "    # Only use samples that have dementia (classes 1, 2, 3)\n",
    "    train_dementia_indices = np.where(y_train > 0)[0]\n",
    "    val_dementia_indices = np.where(y_val > 0)[0]\n",
    "    \n",
    "    X_train_dementia = X_train[train_dementia_indices]\n",
    "    y_train_dementia = y_train[train_dementia_indices] - 1  # Adjust labels to be 0, 1, 2\n",
    "    \n",
    "    X_val_dementia = X_val[val_dementia_indices]\n",
    "    y_val_dementia = y_val[val_dementia_indices] - 1  # Adjust labels to be 0, 1, 2\n",
    "    \n",
    "    # Convert to one-hot encoding\n",
    "    y_train_dementia = to_categorical(y_train_dementia, num_classes=3)\n",
    "    y_val_dementia = to_categorical(y_val_dementia, num_classes=3)\n",
    "    \n",
    "    # Data augmentation\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest'\n",
    "    )\n",
    "    \n",
    "    val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "    \n",
    "    train_generator = train_datagen.flow(X_train_dementia, y_train_dementia, batch_size=32)\n",
    "    val_generator = val_datagen.flow(X_val_dementia, y_val_dementia, batch_size=32)\n",
    "    \n",
    "    # Build model\n",
    "    severity_model = Sequential([\n",
    "        Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 1), kernel_regularizer=l2(0.001)),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        \n",
    "        Conv2D(64, (3, 3), activation='relu', kernel_regularizer=l2(0.001)),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        \n",
    "        Conv2D(128, (3, 3), activation='relu', kernel_regularizer=l2(0.001)),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        \n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu', kernel_regularizer=l2(0.001)),\n",
    "        Dropout(0.5),\n",
    "        Dense(3, activation='softmax')  # 3 classes: Mild, Moderate, Very Mild\n",
    "    ])\n",
    "    \n",
    "    # Compile model\n",
    "    severity_model.compile(\n",
    "        optimizer=Adam(learning_rate=0.0001),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    # Callbacks\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.00001)\n",
    "    \n",
    "    # Train model\n",
    "    history = severity_model.fit(\n",
    "        train_generator,\n",
    "        validation_data=val_generator,\n",
    "        epochs=50,\n",
    "        callbacks=[early_stopping, reduce_lr]\n",
    "    )\n",
    "    \n",
    "    return severity_model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_hierarchical(binary_model, severity_model, image):\n",
    "    # Preprocess image\n",
    "    img = cv2.resize(image, (224, 224))\n",
    "    img = img / 255.0\n",
    "    img = img.reshape(1, 224, 224, 1)\n",
    "    \n",
    "    # Stage 1: Binary classification\n",
    "    binary_pred = binary_model.predict(img)[0][0]\n",
    "    \n",
    "    if binary_pred < 0.5:  # Threshold can be adjusted\n",
    "        return \"Non-Demented\", binary_pred, None\n",
    "    else:\n",
    "        # Stage 2: Severity classification\n",
    "        severity_pred = severity_model.predict(img)[0]\n",
    "        severity_class = np.argmax(severity_pred)\n",
    "        \n",
    "        severity_labels = [\"Mild Dementia\", \"Moderate Dementia\", \"Very Mild Dementia\"]\n",
    "        return severity_labels[severity_class], binary_pred, severity_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Import necessary libraries\n",
    "# import os\n",
    "# import random\n",
    "# import numpy as np\n",
    "# import cv2\n",
    "# from collections import Counter\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "# from tensorflow.keras.optimizers import Adam\n",
    "# from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "# from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "# from tensorflow.keras.utils import to_categorical\n",
    "# from tensorflow.keras.regularizers import l2\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# # Load and prepare data\n",
    "# image_paths, binary_labels, detailed_labels, subjects = prepare_binary_data()\n",
    "\n",
    "# # Ensure data distribution is balanced\n",
    "# print(\"Binary labels:\", np.bincount(binary_labels))\n",
    "\n",
    "# X = load_images(image_paths)\n",
    "\n",
    "# # Split data by subject\n",
    "# train_indices, val_indices = split_by_subject(image_paths, binary_labels, detailed_labels, subjects)\n",
    "\n",
    "# # Create train/val datasets\n",
    "# X_train = X[train_indices]\n",
    "# y_train_binary = binary_labels[train_indices]\n",
    "# y_train_detailed = detailed_labels[train_indices]\n",
    "\n",
    "# X_val = X[val_indices]\n",
    "# y_val_binary = binary_labels[val_indices]\n",
    "# y_val_detailed = detailed_labels[val_indices]\n",
    "\n",
    "# # Reshape to include channel dimension\n",
    "# X_train = X_train[..., np.newaxis]\n",
    "# X_val = X_val[..., np.newaxis]\n",
    "\n",
    "# # Train binary classifier\n",
    "# binary_model, binary_history = train_binary_classifier(X_train, y_train_binary, X_val, y_val_binary)\n",
    "\n",
    "# # Train severity classifier\n",
    "# # severity_model, severity_history = train_severity_classifier(X_train, y_train_detailed, X_val, y_val_detailed)\n",
    "\n",
    "# # Save models\n",
    "# binary_model.save('binary_classifier.h5')\n",
    "# # severity_model.save('severity_classifier.h5')\n",
    "\n",
    "# # Evaluate models\n",
    "# binary_eval = binary_model.evaluate(X_val, y_val_binary)\n",
    "# print(f\"Binary classifier - Validation Loss: {binary_eval[0]:.4f}, Validation Accuracy: {binary_eval[1]:.4f}\")\n",
    "\n",
    "# # Evaluate severity classifier on dementia samples only\n",
    "# # val_dementia_indices = np.where(y_val_detailed > 0)[0]\n",
    "# # X_val_dementia = X_val[val_dementia_indices]\n",
    "# # y_val_dementia = y_val_detailed[val_dementia_indices] - 1  # Adjust to 0-based\n",
    "# # y_val_dementia_cat = to_categorical(y_val_dementia, num_classes=3)\n",
    "\n",
    "# # severity_eval = severity_model.evaluate(X_val_dementia, y_val_dementia_cat)\n",
    "# # print(f\"Severity classifier - Validation Loss: {severity_eval[0]:.4f}, Validation Accuracy: {severity_eval[1]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Two Stage Hierarchical Classifier for AD\n",
    "This approach will:\n",
    "1. First classify images as \"Dementia\" vs \"Non-Dementia\" (binary classification)\n",
    "2. Then classify \"Dementia\" images into severity levels (multi-class classification)\n",
    "    * Will implement later if binary works well\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation and pre processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_balanced_data():\n",
    "    \"\"\"\n",
    "    Prepares data with balanced subjects across classes\n",
    "    Returns: image_paths, binary_labels, detailed_labels, subjects\n",
    "    \"\"\"\n",
    "    # Dataset path\n",
    "    dataset_path = './OASIS Data'\n",
    "    \n",
    "    # Initialize lists\n",
    "    image_paths = []\n",
    "    binary_labels = []  # 0 for Non-Demented, 1 for any type of Dementia\n",
    "    detailed_labels = []  # 0: Non-Demented, 1: Mild, 2: Moderate, 3: Very Mild\n",
    "    subjects = []\n",
    "    \n",
    "    # Dictionary to track subjects and their classes\n",
    "    subject_images = {}  # {subject_id: [(image_path, binary_label, detailed_label), ...]}\n",
    "    \n",
    "    print(f\"Accessing dataset from: {dataset_path}\")\n",
    "    \n",
    "    # Process Non-Demented images\n",
    "    non_demented_path = os.path.join(dataset_path, 'Non Demented')\n",
    "    print(f\"Loading Non-Demented images from: {non_demented_path}\")\n",
    "    non_demented_files = os.listdir(non_demented_path)\n",
    "    print(f\"Found {len(non_demented_files)} Non-Demented files\")\n",
    "    \n",
    "    # Process all non-demented files\n",
    "    for image_filename in non_demented_files:\n",
    "        if not os.path.isfile(os.path.join(non_demented_path, image_filename)):\n",
    "            continue\n",
    "            \n",
    "        # Extract subject ID\n",
    "        try:\n",
    "            subject_id = image_filename.split('OAS1_')[1].split('_')[0]\n",
    "        except:\n",
    "            print(f\"Skipping file with invalid format: {image_filename}\")\n",
    "            continue\n",
    "            \n",
    "        image_path = os.path.join(non_demented_path, image_filename)\n",
    "        \n",
    "        # Add to subject dictionary\n",
    "        if subject_id not in subject_images:\n",
    "            subject_images[subject_id] = []\n",
    "        subject_images[subject_id].append((image_path, 0, 0))  # (path, binary_label, detailed_label)\n",
    "    \n",
    "    # Process dementia classes\n",
    "    dementia_classes = {\n",
    "        'Mild Dementia': 1,\n",
    "        'Moderate Dementia': 2,\n",
    "        'Very mild Dementia': 3\n",
    "    }\n",
    "    \n",
    "    for category, label in dementia_classes.items():\n",
    "        category_path = os.path.join(dataset_path, category)\n",
    "        print(f\"Loading {category} images from: {category_path}\")\n",
    "        category_files = os.listdir(category_path)\n",
    "        print(f\"Found {len(category_files)} {category} files\")\n",
    "        \n",
    "        for image_filename in category_files:\n",
    "            if not os.path.isfile(os.path.join(category_path, image_filename)):\n",
    "                continue\n",
    "                \n",
    "            # Extract subject ID\n",
    "            try:\n",
    "                subject_id = image_filename.split('OAS1_')[1].split('_')[0]\n",
    "            except:\n",
    "                print(f\"Skipping file with invalid format: {image_filename}\")\n",
    "                continue\n",
    "                \n",
    "            image_path = os.path.join(category_path, image_filename)\n",
    "            \n",
    "            # Add to subject dictionary\n",
    "            if subject_id not in subject_images:\n",
    "                subject_images[subject_id] = []\n",
    "            subject_images[subject_id].append((image_path, 1, label))  # (path, binary_label, detailed_label)\n",
    "    \n",
    "    # Analyze subject distribution\n",
    "    subject_class = {}  # {subject_id: binary_class}\n",
    "    for subject_id, images in subject_images.items():\n",
    "        # Determine the majority class for this subject\n",
    "        class_counts = Counter([img[1] for img in images])\n",
    "        majority_class = class_counts.most_common(1)[0][0]\n",
    "        subject_class[subject_id] = majority_class\n",
    "    \n",
    "    # Count subjects per class\n",
    "    class0_subjects = [s for s, c in subject_class.items() if c == 0]\n",
    "    class1_subjects = [s for s, c in subject_class.items() if c == 1]\n",
    "    \n",
    "    print(f\"Found {len(class0_subjects)} subjects in class 0 (Non-Demented)\")\n",
    "    print(f\"Found {len(class1_subjects)} subjects in class 1 (Dementia)\")\n",
    "    \n",
    "    # Balance number of subjects per class if needed\n",
    "    min_subjects = min(len(class0_subjects), len(class1_subjects))\n",
    "    if len(class0_subjects) > min_subjects:\n",
    "        class0_subjects = random.sample(class0_subjects, min_subjects)\n",
    "    if len(class1_subjects) > min_subjects:\n",
    "        class1_subjects = random.sample(class1_subjects, min_subjects)\n",
    "    \n",
    "    print(f\"Using {len(class0_subjects)} subjects from each class for balance\")\n",
    "    \n",
    "    # Collect all images from selected subjects\n",
    "    selected_subjects = class0_subjects + class1_subjects\n",
    "    \n",
    "    for subject_id in selected_subjects:\n",
    "        for img_path, binary_label, detailed_label in subject_images[subject_id]:\n",
    "            image_paths.append(img_path)\n",
    "            binary_labels.append(binary_label)\n",
    "            detailed_labels.append(detailed_label)\n",
    "            subjects.append(subject_id)\n",
    "    \n",
    "    # Convert to numpy arrays\n",
    "    binary_labels = np.array(binary_labels)\n",
    "    detailed_labels = np.array(detailed_labels)\n",
    "    \n",
    "    # Print statistics\n",
    "    print(f\"Total images: {len(image_paths)}\")\n",
    "    print(f\"Total subjects: {len(set(subjects))}\")\n",
    "    print(f\"Binary label distribution: {np.bincount(binary_labels)}\")\n",
    "    \n",
    "    # Print detailed statistics\n",
    "    subject_counter = Counter(subjects)\n",
    "    print(f\"Number of unique subjects: {len(subject_counter)}\")\n",
    "    print(f\"Average images per subject: {len(subjects) / len(subject_counter):.1f}\")\n",
    "    print(f\"Top 10 subjects by image count: {sorted(subject_counter.items(), key=lambda x: x[1], reverse=True)[:10]}\")\n",
    "    \n",
    "    return image_paths, binary_labels, detailed_labels, subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Subject based train/validation split to prevent data leakage. This ensures that the demented class has a balanced distribution of subjects in the train and validation sets.\n",
    "\n",
    "This script works by first getting the unique subjects found from prepare_binary_data().\n",
    "\n",
    "Then, it creates a mapping of subjects to their binary classes.\n",
    "\n",
    "Finally, it splits the data into train and validation sets.\n",
    "\"\"\"\n",
    "\n",
    "def split_by_subject(image_paths, binary_labels, detailed_labels, subjects):\n",
    "    # Get unique subjects\n",
    "    subject_counter = Counter(subjects)\n",
    "    print(f\"Number of unique subjects: {len(subject_counter)}\")\n",
    "    print(f\"Average images per subject: {len(subjects) / len(subject_counter):.1f}\")\n",
    "    print(f\"Subject distribution: {sorted(subject_counter.items(), key=lambda x: x[1], reverse=True)[:10]}\")\n",
    "    \n",
    "    # Create a mapping of subjects to their classes (for stratified split)\n",
    "    subject_to_binary_class = {}\n",
    "    for i, subject in enumerate(subjects):\n",
    "        if subject not in subject_to_binary_class:\n",
    "            subject_to_binary_class[subject] = binary_labels[i]\n",
    "\n",
    "    print(f'Subject to binary class: {subject_to_binary_class}')\n",
    "    \n",
    "    # Get subjects for each binary class\n",
    "    class0_subjects = [s for s, c in subject_to_binary_class.items() if c == 0]\n",
    "    class1_subjects = [s for s, c in subject_to_binary_class.items() if c == 1]\n",
    "    print(f'Class 0 subjects: {class0_subjects}')\n",
    "    print(f'Class 1 subjects: {class1_subjects}')\n",
    "\n",
    "    # Split each class separately to maintain class distribution\n",
    "    train_class0, val_class0 = train_test_split(class0_subjects, test_size=0.2, random_state=42)\n",
    "    train_class1, val_class1 = train_test_split(class1_subjects, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Combine\n",
    "    train_subjects = train_class0 + train_class1\n",
    "    val_subjects = val_class0 + val_class1\n",
    "    \n",
    "    # Get indices for train and validation\n",
    "    train_indices = [i for i, subject in enumerate(subjects) if subject in train_subjects]\n",
    "    val_indices = [i for i, subject in enumerate(subjects) if subject in val_subjects]\n",
    "    \n",
    "    return train_indices, val_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load images\n",
    "def load_images(paths, img_size=(224, 224)):\n",
    "    images = []\n",
    "    for path in paths:\n",
    "        try:\n",
    "            img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "            if img is None:\n",
    "                print(f\"Failed to load image: {path}\")\n",
    "                continue\n",
    "            img = cv2.resize(img, img_size)\n",
    "            images.append(img)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing image {path}: {str(e)}\")\n",
    "    return np.array(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We are working with this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_with_group_kfold(n_splits=5, epochs=20):\n",
    "    \"\"\"\n",
    "    Train the model using GroupKFold cross-validation\n",
    "    to properly handle subject-based splitting\n",
    "    \"\"\"\n",
    "    # Prepare data\n",
    "    image_paths, binary_labels, detailed_labels, subjects = prepare_balanced_data()\n",
    "    \n",
    "    # Create a mapping of subjects to their classes\n",
    "    subject_class = {}\n",
    "    for i, subject in enumerate(subjects):\n",
    "        subject_class[subject] = binary_labels[i]\n",
    "    \n",
    "    # Load images\n",
    "    print(\"Loading images...\")\n",
    "    X = load_images(image_paths)\n",
    "    y = binary_labels\n",
    "    groups = np.array(subjects)\n",
    "    \n",
    "    # Setup GroupKFold\n",
    "    gkf = GroupKFold(n_splits=n_splits)\n",
    "    \n",
    "    # Store results\n",
    "    fold_results = []\n",
    "    \n",
    "    # Train on each fold\n",
    "    for fold, (train_idx, val_idx) in enumerate(gkf.split(X, y, groups)):\n",
    "        print(f\"\\n===== Training fold {fold+1}/{n_splits} =====\")\n",
    "        \n",
    "        # Split data\n",
    "        X_train, X_val = X[train_idx], X[val_idx]\n",
    "        y_train, y_val = y[train_idx], y[val_idx]\n",
    "        \n",
    "        # Print fold statistics\n",
    "        print(f\"Training samples: {len(X_train)}, Validation samples: {len(X_val)}\")\n",
    "        print(f\"Training class distribution: {np.bincount(y_train)}\")\n",
    "        print(f\"Validation class distribution: {np.bincount(y_val)}\")\n",
    "        \n",
    "        # Count unique subjects in each split\n",
    "        train_subjects = set([groups[i] for i in train_idx])\n",
    "        val_subjects = set([groups[i] for i in val_idx])\n",
    "        # Improved version:\n",
    "        # Create a dictionary mapping subject IDs to their classes for better visibility\n",
    "        train_subject_classes = {subject: subject_class.get(subject, 'Unknown') for subject in train_subjects}\n",
    "        val_subject_classes = {subject: subject_class.get(subject, 'Unknown') for subject in val_subjects}\n",
    "\n",
    "        # Print detailed information\n",
    "        print(f\"Training subjects: {len(train_subjects)}\")\n",
    "        for subject, cls in train_subject_classes.items():\n",
    "            class_name = \"Non-Demented\" if cls == 0 else \"Dementia\" if cls == 1 else \"Unknown\"\n",
    "            print(f\"  - Subject {subject}: Class {cls} ({class_name})\")\n",
    "            \n",
    "        print(f\"\\nValidation subjects: {len(val_subjects)}\")\n",
    "        for subject, cls in val_subject_classes.items():\n",
    "            class_name = \"Non-Demented\" if cls == 0 else \"Dementia\" if cls == 1 else \"Unknown\"\n",
    "            print(f\"  - Subject {subject}: Class {cls} ({class_name})\")\n",
    "        \n",
    "        # Verify no subject overlap\n",
    "        assert len(train_subjects.intersection(val_subjects)) == 0, \"Subject leakage detected!\"\n",
    "        \n",
    "        # Reshape to include channel dimension\n",
    "        X_train = X_train[..., np.newaxis]\n",
    "        X_val = X_val[..., np.newaxis]\n",
    "        \n",
    "        # Create data generators with augmentation\n",
    "        train_datagen = ImageDataGenerator(\n",
    "            rescale=1./255,  # Normalize pixel values\n",
    "            rotation_range=15,  # Rotate images\n",
    "            width_shift_range=0.1,  # Shift horizontally\n",
    "            height_shift_range=0.1,  # Shift vertically\n",
    "            shear_range=0.1,  # Shear\n",
    "            zoom_range=0.1,  # Zoom\n",
    "            horizontal_flip=True,  # Flip horizontally\n",
    "            fill_mode='nearest'  # Fill strategy\n",
    "        )\n",
    "        \n",
    "        val_datagen = ImageDataGenerator(rescale=1./255)  # Only normalize validation data\n",
    "        \n",
    "        # Create generators\n",
    "        train_generator = train_datagen.flow(X_train, y_train, batch_size=32)\n",
    "        val_generator = val_datagen.flow(X_val, y_val, batch_size=32)\n",
    "        \n",
    "        # Build model with regularization to prevent overfitting\n",
    "        model = Sequential([\n",
    "            # First convolutional block\n",
    "            Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 1), \n",
    "                   kernel_regularizer=l2(0.001), padding='same'),\n",
    "            MaxPooling2D(pool_size=(2, 2)),\n",
    "            \n",
    "            # Second convolutional block\n",
    "            Conv2D(64, (3, 3), activation='relu', kernel_regularizer=l2(0.001), padding='same'),\n",
    "            MaxPooling2D(pool_size=(2, 2)),\n",
    "            \n",
    "            # Third convolutional block\n",
    "            Conv2D(128, (3, 3), activation='relu', kernel_regularizer=l2(0.001), padding='same'),\n",
    "            MaxPooling2D(pool_size=(2, 2)),\n",
    "            \n",
    "            # Flatten and dense layers\n",
    "            Flatten(),\n",
    "            Dense(128, activation='relu', kernel_regularizer=l2(0.001)),\n",
    "            Dropout(0.5),  # Strong dropout to prevent overfitting\n",
    "            Dense(1, activation='sigmoid')\n",
    "        ])\n",
    "        \n",
    "        # Compile model\n",
    "        model.compile(\n",
    "            optimizer=Adam(learning_rate=0.0001),  # Low learning rate\n",
    "            loss='binary_crossentropy',\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "        \n",
    "        # Print model summary\n",
    "        model.summary()\n",
    "        \n",
    "        # Callbacks\n",
    "        early_stopping = EarlyStopping(\n",
    "            monitor='val_loss', \n",
    "            patience=10,  # Wait for 10 epochs before stopping\n",
    "            restore_best_weights=True,  # Restore weights from best epoch\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        reduce_lr = ReduceLROnPlateau(\n",
    "            monitor='val_loss',\n",
    "            factor=0.2,  # Reduce LR by 80% when plateauing\n",
    "            patience=5,\n",
    "            min_lr=0.00001,\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        # Train model\n",
    "        history = model.fit(\n",
    "            train_generator,\n",
    "            validation_data=val_generator,\n",
    "            epochs=epochs,\n",
    "            callbacks=[early_stopping, reduce_lr],\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        # Evaluate model\n",
    "        val_loss, val_acc = model.evaluate(val_generator, verbose=0)\n",
    "        fold_results.append(val_acc)\n",
    "        \n",
    "        print(f\"Fold {fold+1} validation accuracy: {val_acc:.4f}\")\n",
    "        \n",
    "        # Save model for this fold\n",
    "        model.save(f'alzheimer_model_fold_{fold+1}.h5')\n",
    "    \n",
    "    # Print overall results\n",
    "    print(\"\\n===== Cross-validation Results =====\")\n",
    "    for i, acc in enumerate(fold_results):\n",
    "        print(f\"Fold {i+1}: {acc:.4f}\")\n",
    "    print(f\"Average validation accuracy: {np.mean(fold_results):.4f}\")\n",
    "    print(f\"Standard deviation: {np.std(fold_results):.4f}\")\n",
    "    \n",
    "    return fold_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import cv2\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import GroupKFold, train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train_with_group_kfold(n_splits=5, epochs=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay this is great cause our model is learning at least. Since we already have such a small dataset, I think the fact that Moderately demented has two unique subjects  heavily skews our learning process. \n",
    "\n",
    "We have 5 unique non-demented subjects, and 10 demented subjects (excluding moderate dementia), so that's 5 entries for each class. How about we keep all 15 unique subjects, and for the demented patients just limit the number of images per subject so that we can have about a 1:1 ratio of images for demented vs. non-demented subjects. \n",
    "\n",
    "Even if the experiment fails, I think the fact that we only have 2 subjects for moderate dementia messes with our data distribution and learning process for the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing Moderately Demented Data and working with balanced subject distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_balanced_data_by_image_count():\n",
    "    \"\"\"\n",
    "    Prepares data with all unique subjects but balances the number of images\n",
    "    per class by limiting images per subject in the larger class.\n",
    "    Returns: image_paths, binary_labels, detailed_labels, subjects\n",
    "    \"\"\"\n",
    "    # Dataset path\n",
    "    dataset_path = './OASIS Data'\n",
    "    \n",
    "    # Initialize lists\n",
    "    image_paths = []\n",
    "    binary_labels = []  # 0 for Non-Demented, 1 for any type of Dementia\n",
    "    detailed_labels = []  # 0: Non-Demented, 1: Mild, 3: Very Mild\n",
    "    subjects = []\n",
    "    \n",
    "    # Dictionary to track subjects and their classes\n",
    "    subject_images = {}  # {subject_id: [(image_path, binary_label, detailed_label), ...]}\n",
    "    \n",
    "    print(f\"Accessing dataset from: {dataset_path}\")\n",
    "    \n",
    "    # Process Non-Demented images\n",
    "    non_demented_path = os.path.join(dataset_path, 'Non Demented')\n",
    "    print(f\"Loading Non-Demented images from: {non_demented_path}\")\n",
    "    non_demented_files = os.listdir(non_demented_path)\n",
    "    print(f\"Found {len(non_demented_files)} Non-Demented files\")\n",
    "    \n",
    "    # Process all non-demented files\n",
    "    for image_filename in non_demented_files:\n",
    "        if not os.path.isfile(os.path.join(non_demented_path, image_filename)):\n",
    "            continue\n",
    "            \n",
    "        # Extract subject ID\n",
    "        try:\n",
    "            subject_id = image_filename.split('OAS1_')[1].split('_')[0]\n",
    "        except:\n",
    "            print(f\"Skipping file with invalid format: {image_filename}\")\n",
    "            continue\n",
    "            \n",
    "        image_path = os.path.join(non_demented_path, image_filename)\n",
    "        \n",
    "        # Add to subject dictionary\n",
    "        if subject_id not in subject_images:\n",
    "            subject_images[subject_id] = []\n",
    "        subject_images[subject_id].append((image_path, 0, 0))  # (path, binary_label, detailed_label)\n",
    "    \n",
    "    # Process dementia classes (excluding Moderate Dementia)\n",
    "    dementia_classes = {\n",
    "        'Mild Dementia': 1,\n",
    "        'Very mild Dementia': 3\n",
    "    }\n",
    "    \n",
    "    for category, label in dementia_classes.items():\n",
    "        category_path = os.path.join(dataset_path, category)\n",
    "        print(f\"Loading {category} images from: {category_path}\")\n",
    "        category_files = os.listdir(category_path)\n",
    "        print(f\"Found {len(category_files)} {category} files\")\n",
    "        \n",
    "        for image_filename in category_files:\n",
    "            if not os.path.isfile(os.path.join(category_path, image_filename)):\n",
    "                continue\n",
    "                \n",
    "            # Extract subject ID\n",
    "            try:\n",
    "                subject_id = image_filename.split('OAS1_')[1].split('_')[0]\n",
    "            except:\n",
    "                print(f\"Skipping file with invalid format: {image_filename}\")\n",
    "                continue\n",
    "                \n",
    "            image_path = os.path.join(category_path, image_filename)\n",
    "            \n",
    "            # Add to subject dictionary\n",
    "            if subject_id not in subject_images:\n",
    "                subject_images[subject_id] = []\n",
    "            subject_images[subject_id].append((image_path, 1, label))  # (path, binary_label, detailed_label)\n",
    "    \n",
    "    # Analyze subject distribution\n",
    "    subject_class = {}  # {subject_id: binary_class}\n",
    "    for subject_id, images in subject_images.items():\n",
    "        # Determine the majority class for this subject\n",
    "        class_counts = Counter([img[1] for img in images])\n",
    "        majority_class = class_counts.most_common(1)[0][0]\n",
    "        subject_class[subject_id] = majority_class\n",
    "    \n",
    "    # Count subjects per class\n",
    "    class0_subjects = [s for s, c in subject_class.items() if c == 0]\n",
    "    class1_subjects = [s for s, c in subject_class.items() if c == 1]\n",
    "    \n",
    "    print(f\"Found {len(class0_subjects)} subjects in class 0 (Non-Demented)\")\n",
    "    print(f\"Found {len(class1_subjects)} subjects in class 1 (Dementia)\")\n",
    "    \n",
    "    # Count total images per class\n",
    "    class0_images = sum(len(subject_images[s]) for s in class0_subjects)\n",
    "    class1_images = sum(len(subject_images[s]) for s in class1_subjects)\n",
    "    \n",
    "    print(f\"Found {class0_images} images in class 0 (Non-Demented)\")\n",
    "    print(f\"Found {class1_images} images in class 1 (Dementia)\")\n",
    "    \n",
    "    # Calculate target number of images per dementia subject to balance classes\n",
    "    target_images_per_dementia_subject = class0_images // len(class1_subjects)\n",
    "    print(f\"Limiting to {target_images_per_dementia_subject} images per dementia subject to balance classes\")\n",
    "    \n",
    "    # Collect all non-demented images\n",
    "    for subject_id in class0_subjects:\n",
    "        for img_path, binary_label, detailed_label in subject_images[subject_id]:\n",
    "            image_paths.append(img_path)\n",
    "            binary_labels.append(binary_label)\n",
    "            detailed_labels.append(detailed_label)\n",
    "            subjects.append(subject_id)\n",
    "    \n",
    "    # Collect limited dementia images\n",
    "    for subject_id in class1_subjects:\n",
    "        # Randomly sample images if we have more than the target\n",
    "        subject_image_list = subject_images[subject_id]\n",
    "        if len(subject_image_list) > target_images_per_dementia_subject:\n",
    "            subject_image_list = random.sample(subject_image_list, target_images_per_dementia_subject)\n",
    "        \n",
    "        for img_path, binary_label, detailed_label in subject_image_list:\n",
    "            image_paths.append(img_path)\n",
    "            binary_labels.append(binary_label)\n",
    "            detailed_labels.append(detailed_label)\n",
    "            subjects.append(subject_id)\n",
    "    \n",
    "    # Convert to numpy arrays\n",
    "    binary_labels = np.array(binary_labels)\n",
    "    detailed_labels = np.array(detailed_labels)\n",
    "    \n",
    "    # Print statistics\n",
    "    print(f\"Total images: {len(image_paths)}\")\n",
    "    print(f\"Total subjects: {len(set(subjects))}\")\n",
    "    print(f\"Binary label distribution: {np.bincount(binary_labels)}\")\n",
    "    \n",
    "    # Print detailed statistics\n",
    "    subject_counter = Counter(subjects)\n",
    "    print(f\"Number of unique subjects: {len(subject_counter)}\")\n",
    "    print(f\"Average images per subject: {len(subjects) / len(subject_counter):.1f}\")\n",
    "    print(f\"Images per subject: {dict(subject_counter)}\")\n",
    "    \n",
    "    return image_paths, binary_labels, detailed_labels, subjects"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
